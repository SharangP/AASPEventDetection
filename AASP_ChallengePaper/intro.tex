The task of event detection and classification is fundamentally important in computational auditory scene analysis (CASA). Detecting events such as words in a sentence of speech, the arrival of a bus or train, or any other common occurrence in an audio stream is the first stage in many speech and audio processing systems. Many such systems then need to classify the detected events in order to take appropriate actions.

In this project submission, the problem of event detection and classification, as applied to an office environment, was approached from a pattern recognition perspective. Our system consists of a segmentation stage, a feature extraction stage, and two classification stages. The first stage detects the onset and offset of events in a live recording, the second extracts features from each event that can be used to classify events, and the final stages classify each detected event
on a frame-by-frame basis using a pre-trained likelihood ratio test (LRT) classifier with a MAP decision rule. The performance of the system is evaluated on three datasets: a 5-fold cross-validation using the training dataset itself, the development set with ``perfect'' segmentation, and the raw development set.
